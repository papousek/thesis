\documentclass[table,color,cover,twoside,nolot,nolof]{fithesis3/fithesis3}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{graphics}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{numprint}
\usepackage{bibentry}
\usepackage[inline]{enumitem}
\nobibliography*
\thesissetup{
	faculty=fi,
	title=Computerized Adaptive Practice of Factual Knowledge,
	type=p,
	author=Jan Papou\v{s}ek,
	advisor=Radek Pel\'{a}nek,
	keywords={varied prior knowledge, adaptive educational system, intelligent
		tutoring system, computerized adaptive practice, factual knowledge, task
		construction},
	basePath=./fithesis3
}
\usepackage[final]{pdfpages}
\usepackage{tabularx}
\usepackage[inline]{enumitem}

\makeatletter\thesis@load\makeatother
\setcounter{tocdepth}{2}

\begin{document}

\chapter{Introduction}

Using computers and other electronic devices becomes more and mo\-re common in
every day life. It is thus natural to use them also in the~domain of
education. We can look at this kind of their application in two different
viewpoints. In the first case they are used to help teachers to spend less
time doing routine tasks and more time with students, to prepare good teaching
materials, to effectively find out what students know and what they do not
know, and so on. Of course this has indirect positive impact on students. In
the second case computers may help students directly as they can serve as a
platform where personalized systems provide adaptive content, e.g.~guide
students in situations when they lag behind or introduce new challenges when
they are able to solve the previous ones. To understand how these systems are
used it is important to realize students usually interact with them with
minimal assistance of teachers.

Although the first case is important we focus on the second one, i.e. on the
way computers can help students directly. We are mainly interested in systems
where students actively solve presented tasks, i.e. in systems for
\emph{computerized adaptive practice}~\cite{klinkenberg2011computer}. According
to~\cite{vanlehn2006behavior} this kind of practice consists of two loops. The
outer loop describes selection of a task to solve and in case of the inner one
a system guides its users in the process of solution of a complex multi-step
task. As the thesis deals with memorizing facts, e.g. vocabulary or
geographical and anatomical terms, that can be done through atomic tasks
without any intermediate steps, the inner loop is not so important for us. The
considered method of practice consists of answering multiple-choice and open
questions, interleaved with a~feedback on the correctness of answers.

Computerized adaptive practice is one way of self-testing. Based on recent
research~\cite{bjork2013self} self-testing is a~good strategy that may boost
students' performance. On the other side people make a lot of mistakes during
the self-testing. They overestimate their knowledge and this overconfidence
leads to worse choice of tasks for
practice~\cite{bjork2013self,kornell2008optimising}. This makes the practice
less efficient than it could be. The second problematic aspect of self-testing
is that although the repetition is good for memorizing, it is not so commonly
used neither by high performers who may not need it, nor by low performers who
are not motivated to use it~\cite{bjork2013self}. A well-designed system for
computerized adaptive practice can address both of these issues. Moreover this
system can operate online and be available to a large number of users, thus
making self-testing a very natural way to learn.

However, in online educational environments we deal with a lot of different
categories of users. It is natural these systems are used by students,
sometimes even at schools for a fixed amount of time. On the other side they
are also open to non-school users willing to improve their knowledge in their
free time. Having diverse set of users means these users have varied
background, motivation and prior knowledge. Whereas some users may want to
learn for a tomorrow exam, others may be more interested in using their
knowledge in the long term. This contrasts with classical educational
environments, i.e. schools, where learners and their motivation do not differ
so much. For that reason the online system providing the practice has to
attract and keep attention of all kinds of users and ensure they spend
their time in the most efficient way with respect to learning. This can be a
bit difficult, because a strategy motivating users to stay active may be
different from a strategy making the practice efficient with respect to
learning.

To provide adaptivity we need to build an adequate model describing user's
knowledge. The model should take into account e.g. prior knowledge, learning or
forgetting. We also need to design a good strategy for practicing, which may
differ for different types of users. We can not design a~good strategy for
practicing when we are not able to measure its impact on a user's motivation and
its efficiency with respect to learning. It is thus crucial to collect data
about users' activity and evaluate it. This turns out to be a big
methodological issue in online environment.

This issue may or may not have been addressed by commercial systems operating
in this area. Unfortunately the functioning of these systems --
e.g.~\url{www.memrise.com} and \url{www.cerego.com} providing practice of
individual terms within several domains, or
\url{www.duolingo.com}~\cite{garcia2013learning} teaching users foreign
languages by asking them to translate sentences (both in writing and in spoken
word) -- is not often properly described. There are, of course, a few
exceptions, like~\cite{streeter2015mixture}.

The aim of the thesis is to address mentioned issues -- student modeling,
strategies for practice control and evaluation -- to make acquiring factual
knowledge more efficient. The outcomes of the thesis will be applied and
evaluated in an online environment, which means they may potentially have a big
impact on learning of a large number of people. They can be also scientifically
influential as they may provide certain hints on the modeling of learning and
on the evaluation methodology.

The state of the art described in Chapter
\ref{chapter:state_of_the_art} is focused on the following three pillars:
\begin{enumerate*}[label=(\arabic*)]
	\item models describing a learner's knowledge and learning;
	\item strategies controlling the practice;
	\item methodologies for evaluation.
\end{enumerate*}
Chapter~\ref{chapter:aims_of_the_thesis} discusses aims of the thesis, its
objectives and the plan of work in more detail.
Chapter~\ref{chapter:achieved_results} consists of brief description of
achieved results.

\chapter{State of the Art}
\label{chapter:state_of_the_art}

Development of a fully adaptive system providing practice of facts requires
insights from a few different areas, such as psychology, cognitive and computer
science. This chapter describes state of the art in these areas focusing on student
modeling, controlling the practice itself and evaluation.

\section{Memory and Learning of Facts}
\label{section:models}

The common way to learn facts whether online or offline is using
flashcards~\cite{kornell2008optimising}. A flashcard has two sides, the first
side represents the term we want to learn and the second one its
explanation, e.g. translation or an image describing it. During a practice
session a sequence of flashcards is presented. Firstly we look at one side of a
flashcard trying to say what is on the second one and then we check whether our
answer is correct. This simple setup has a few parameters which need to be
considered:

\begin{enumerate}
	\item How many flashcards should be available in a practice session?
	\item What is their optimal order?
	\item Should we drop some flashcards once we think we already know it?
	\item Should we gradually add flashcards with new terms and under what conditions?
	\item How many times should we repeat the same flashcard?
	\item What is the optimal time space between individual presentations of a flashcard?
\end{enumerate}

\subsection{Spacing Effect}
\label{section:spacing_effect}
All of the above-mentioned questions relate to the \emph{spacing
effect} and \emph{forgetting curves} originally discovered by Hermann
Ebbinghaus~\cite{ebbinghaus1885spacing}~(as cited
in~\cite{pavlik2005practice}). When the terms are practiced with more time
space between individual presentations, a learner's performance during the
practice itself is reduced. However, it has a positive impact on
learning in the long term~\cite{maass2015how, kornell2009optimising}. This
contrasts with the way students usually prepare before exams when they prefer
\emph{massed repetition} (also known as \emph{cramming}), i.e. intensive work
to absorb large volume of knowledge in short time period.

\begin{figure}
	\begin{center}
		\includegraphics[width=.6\textwidth]{figure/forgetting_curves}
		\caption{Forgetting curve introduced by Ebbinghaus is given by a
			formula $R = e^{-\frac{t}{S}}$, where $R$ stands for the memory retention, $t$
			for the time and $S$ for the relative strength of memory. Ebbinghaus
			realized that when the information is reminded of again, it strengthens not
			only the memory retention, but also also reduces the forgetting rate.}
	\end{center}
\end{figure}

In the context of computerized adaptive practice we may look at the spacing
effect from two different points of view. In the first case we want to control
it within one session. Here we have full control over it and we work with
seconds, minutes or hours (maximally). With a fixed number of items for
practice we regulate the spacing by modifying the sequence of practiced items,
e.g. we use more blocking or interleaving version of
practice~\cite{ostrow2015blocking}. With variable set of items we can also
decide which items do not have to be practiced
anymore~\cite{kornell2008optimising} or which new items can be included.
Computerized adaptive practice may prove useful in this specific case, i.e. the
case when only one session is carried out, as while sequencing has a big
impact on learners' performance~\cite{ostrow2015blocking}, people are not able to
to judge which items they have already mastered~\cite{kornell2008optimising}
and which ones they should practice~\cite{kornell2014focusing}.

In the second case we plan the practice over more
sessions~\cite{kang2014retrieval}. It would be ideal if a system could decide when a
session starts and when it ends. However, this decision is, of course, made by a user,
not by the system. Thus we can only motivate users to practice regularly, e.g.
every day similarly how it is done by Duolingo (a system for learning
languages)~\cite{garcia2013learning}. This regularity allows us to strengthen
knowledge of already learned items and introduce new ones.

\subsection{Models Overview}

To provide appropriate content a system must be able to model learners,
especially their knowledge. In the following section we provide a brief
overview of so far available models.

\paragraph*{Rasch Model} is known as the one-parameter logistic model in item
response theory~\cite{de2008theory}. It assumes a student's knowledge about
an item is constant and can be expressed as a skill parameter $\theta$. Each
item is also assigned a difficulty parameter $b$. Having these parameters
the probability of correct answer is given by the logistic function:

\begin{align}
P(correct|\theta,b) = \frac{1}{1 + e^{-(\theta - b)}}
\end{align}

Parameters of this model are usually estimated based on data using the joint
maximum likelihood estimation~\cite{de2008theory}. In an online environment it is
useful to update the parameters on the fly. For this purpose we can seek
inspiration in the Elo rating system~\cite{elo1978rating} originally devised for
rating chess players and look at a student's answer related to an item as a
match between the student and the item~\cite{papousek2014adaptive}. If our
estimation is based only on the first interactions between students and items,
the algorithm works for constant skills and difficulties, although the original
Elo system assumes learning (changing skill).

\paragraph*{Bayesian Knowledge Tracing} is commonly used model for
acquiring procedural knowledge~\cite{van2013properties}. It models a student's
knowledge using a hidden Markov model as a binary latent variable (either learned
or unlearned). The model has four parameters: probability the given skill is
initially learned, probability of learning the skill in one step, probability of
a wrong answer when the skill is learned (slip), and probability of a correct
answer when the skill is not learned (guess). Skill estimation is updated using
a Bayes rule based on observed answers. Several extensions of this model can be
found, e.g. one including forgetting~\cite{qiu2010does}.

\paragraph*{Performance Factor Analysis} is a logistic model, but in contrast
to the Rasch model it handles learning~\cite{pavlik2009performance}. The
skill is represented as a linear combination of an item's difficulty ($\beta$)
and the number of past successes ($s$) and failures ($f$) of a student.

\begin{align}
P(correct|\beta,s, f) = \frac{1}{1 + e^{-(\beta + \gamma s + \delta f)}}
\end{align}

Parameter $\gamma$ stands for the change of the skill associated with a correct
answer and $\delta$ stands for the same in case of an incorrect answer.

\paragraph*{Adaptive Character of Thought-Rational} is another logistic model
handling learning and forgetting~\cite{pavlik2005practice}. For each
presentation $i$ of an item we track amount of time $t_i$ that elapsed since
it. The activation $m$ of the item is a function of these times:

\begin{align}
m_n(t_1, \ldots, t_n) = ln\left(\sum_{i=1}^n t_i^{-d}\right)
\end{align}

Parameter $d$ represents decay in time. To get probability that a learner recalls
the item correctly, we apply the logistic function, $P(correct|m) = \frac{1}{1
+ e^{m}}$.\footnote{The equation is simplified. The original model contains more parameters. For more details see~\cite{pavlik2005practice}.} The model can be extended to cover also the spacing
effect once we make the decay parameter dynamic, e.g. dependent directly on
spacing or the previous activation level~\cite{anderson1991reflections} (as
cited in~\cite{pavlik2005practice}).

\bigskip

\noindent
In many areas of learning of facts people enter a tutoring system
with varied prior knowledge, e.g. in case of vocabulary or geography. The
system needs to quickly assess what a learner knows to be able to adaptively
provide appropriate content. This feature is often missing in systems
and users are forced to go through a lot of useless content. Our recent
work~\cite{papousek2014adaptive} similarly to~\cite{khajah2014integrating}
combines a model assuming a constant skill with another one covering learning
to handle this phenomenon. But this should go even further and models should
also provide different learning~\cite{pelanek2015modeling} and forgetting rates
for different items. A model using a mixture of individual learning curves
implemented within Duolingo~\cite{streeter2015mixture} already covers some of
these aspects, but the authors do not pay much attention to prior knowledge and
ignore the spacing effect. On the other side studies that do deal with the
spacing effect are usually based on observations made in a laboratory during
artificial experiments. In these experiments people, for instance, learn
generally unknown terms so that their prior knowledge is
prevented~\cite{kang2014retrieval} or are given no corrective-feedback
during retrieval practice~\cite{landauer1978optimum}~(as cited
in~\cite{kang2014retrieval}). It is thus questionable how all these studies can
contribute to improvement of real educational systems.

\section{Practice Control}
\label{section:practice_control}

As we present in the introduction we focus on the \emph{outer loop}
of a user's practice~\cite{vanlehn2006behavior}, mainly within one session, that
is on sequencing of items presented to the user. The reason is that the
considered area of learning of facts does not provide sufficiently complex
tasks to deal with the \emph{inner loop} (e.g.
hints)~\cite{vanlehn2006behavior}. The practice itself consists of a sequence
of multiple-choice and open questions and we have to decide not only which item
should be practiced, but also whether and how many options the question should
have and in case of multiple-choice questions which items should be used as
distractors. Sequencing should also take into account the spacing effect and
forgetting described in Section~\ref{section:spacing_effect}.

\subsection{Sequencing}

By sequencing the items presented to a user we balance between two states:
\emph{over-practice} and \emph{under-practice}. In the first case a user practices
an already learned item and her time is wasted. In the second one we prevent the user from
practicing an item which is not learned yet and we do not give her a chance
to learn it properly. When a system tries to avoid over-practiced attempts,
there is a high chance that under-practice increases and vice versa. How this
phenomenon is important is presented in a study~\cite{cen2007over}. Its
authors, analyzing collected data, report they detected more than $50\%$ out of
practice attempts as over-practiced.

In a lot of used systems a general approach for sequencing the items is based
on labeling by an expert. The experts define knowledge components for the
given domain and dependencies among them. There are
techniques helping the ex\-perts~\cite{niznan2014using} or completely replacing
them with a computer~\cite{boros2013automatic}. However, these techniques are
rarely used. Each component is a set of items and one item can be
included in more components. We can practice items belonging to one component
as long as a user has mastered all of its prerequisites, but not the component
itself. This edge of knowledge is also known as the \emph{zone of proximal
development}~\cite{lee2005signifying}.

The mastery is detected by a model predicting a user's performance and we say
that the user masters the knowledge component when the predicted probability
the user learned the component exceeds the \emph{mastery threshold} which is
usually set to~$95\%$. The mastery threshold can be viewed as a parameter
controlling the relative frequency of under-practiced and over-practiced
attempts~\cite{fancsali2013optimal}. Since our model needs data about a user to
make an estimation of users' knowledge, there is a low acceptable number of
attempts after the knowledge is acquired. This \emph{lag} is studied in more
details in~\cite{fancsali2013optimal}, but the study is limited to
\emph{Bayesian knowledge tracing} only. Another \emph{when-to-stop} policy is
based on the expected improvement in knowledge~\cite{rollinson2015predictive}.
When the system expects the improvement in knowledge of a domain
below a certain threshold, it stops the user from practicing it. Low expected
improvement indicates an already mastered domain or the domain which can not be
mastered by the user were encountered.

Similar approach is presented in~\cite{lopes2015multi}. It relies
on~\emph{multi-armed bandits}, a technique able to explore
space of different parameters or strategies with respect to a chosen scoring
function. The authors define a structure of activities and pre-conditions
analogical to knowledge components and prerequisites and introduce two
algorithms optimizing users' learning. The first one is independent on any
model estimating users' performance, the second algorithm uses one. Both of
them take information from experts and measure users' learning online based on
progress in users' performance. At time $t$, the measure compares the success
of the last $\frac{d}{2}$ samples with the $\frac{d}{2}$ previous ones. This
way, learning can be estimated thanks to the fact the system measures and
improves users' performance at the same time. We show in
Section~\ref{section:evaluation} this can not be done in some systems.

In some cases the approach using a graph of prerequisites makes sense, e.g.
in algebra we have a strong structure of prerequisites among the knowledge
components (addition and multiplication) and the choice of an item (exercise)
from the knowledge component is not so important, if we know that all
prerequisites for the given component are mastered. On the other hand in case
of a system for learning of vocabulary, individual items are independent, so there is
one item per knowledge component. Of course we can build a structure of
categories and prerequisites, but they represent a recommended study plan
rather than the necessary learning path. When a user enters the system, she can
theoretically start practicing anything.

In~\cite{papousek2014adaptive} and~\cite{papousek2015impact} we present an
approach mainly based on target difficulty. We assume we already have an
estimation a user's performance for each item available in our system,
together with other descriptive information like number of interactions with
the item, last time when the user interacted with it and so on. Since the
estimation is based only on historical data we do not need any experts' input.
On the other side we are fully dependent on the choice of target difficulty and
although there are studies about it~\cite{lomas2013optimizing,
lomas2014optimizing,jansen2013influence,papousek2015impact}, further research
has to be done in this area. Several systems has this parameter set
arbitrarily, e.g. to 75\% chance of a correct
answer~\cite{klinkenberg2011computer}.

As we present in Section~\ref{section:spacing_effect}, learning of facts highly
relates to time and the spacing effect. From this point of view the schedule of
practice was already studied~\cite{pavlik2008schedule}, but in a different
context, in a laboratory with a low number of items and without any prior
knowledge. Figure~\ref{figure:practice_progress} shows how the spacing effect
relates to the content of practice and the number of practiced items.

\begin{figure}
	\begin{subfigure}[b]{.5\textwidth}
		\centering
		\includegraphics[width=0.9\textwidth]{figure/practice_progress_a}
		\caption{high spacing}
		\label{figure:practice_progress_a}
	\end{subfigure}
	\begin{subfigure}[b]{.5\textwidth}
		\centering
		\includegraphics[width=0.9\textwidth]{figure/practice_progress_b}
		\caption{low spacing}
		\label{figure:practice_progress_b}
	\end{subfigure}
	\caption{Visualization of practice with different spacing, each column
		corresponds to an item, each row represents a discrete time unit. Black
		boxes stands for practice attempts.}
	\label{figure:practice_progress}
\end{figure}

\subsection{Questions}

Assume we have already picked an item for practice which corresponds to a
flashcard with two sides $A$ and $B$. We need to specify a direction of the
question (whether we ask for the side $A$ or $B$), e.g. in case of
vocabulary the first direction leads to an ability of understanding a foreign
language and the second one to an ability of expressing ideas in it. In both
ways we want to achieve so-called \emph{cued recall}~\cite{carpenter2006types}.

Once we select a direction we need to decide whether the question will be
open or how many options it will have. Using the options we allow a user
to guess the correct answer, so we make the question easier.
Figure~\ref{figure:options_vs_spacing} shows how the number of options,
together with spacing which is controlled by sequencing, relate to difficulty
of the question. If our only goal is to make the difficulty of a user's practice
appropriate, it is not clear which combination of spacing and number of options
we should use.

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=.5\textwidth]{figure/options_vs_spacing}
	\end{center}
	\caption{Graph illustrating how difficulty depends on spacing and number of
		options. Darker background color means more difficult practice.}
	\label{figure:options_vs_spacing}
\end{figure}

The next issue is how exactly the options themselves should be chosen. We
assume too easy options make the guess probability so high, a user is not
motivated to learn anything. The impact of competitiveness of options has been
studied in~\cite{little2015optimizing}. The study contains two experiments.
The first one does not include feedback about the correctness of a user's
answer, so its results can be hardly applied within a system where the
feedback is present. Based on the second experiment where the feedback was
included, competitive options seem to be a better choice. However, the second
experiment was very limited, so this phenomenon is worth further investigation.

Another aspect related to the competitiveness of options is repeating the
same mistakes. Authors in~\cite{marsh2007memorial} describe experiments where
wrong answers in the final test are correlated to wrong answers given during a
preparation phase where multiple-choice questions were used. These observations
should be definitely taken into account when the options are constructed by
a system for computerized adaptive practice.

\section{Evaluation}
\label{section:evaluation}

Any effort to improve any kind of intelligent tutoring system would be useless
if we were not able to measure some of its features. Design of these
adaptive systems and choice of their parameters are really difficult and then
their adaptive behavior is hard to predict, so it is crucial to be sure they
meet our expectations. We want to improve a user's learning, but due to
the fact that systems for computerized adaptive practice are meant to be used
by people also in their free time, we have to primarily ensure people are
willing to use them. How these things can relate to each other is studied
in~\cite{lomas2013optimizing}.

Since a lot of systems collect data about users' performance and their
behavior is based on models predicting the performance, it is natural to
evaluate new models using the historical data with respect to their accuracy.
We can also try to find whether the behavior of the system would change, if it
used a different model. We can also deploy a new feature, collect new data and then
see what has changed. However, this is really expensive, because we
force users to spend their time on testing our system instead of on learning
something. The last way to examine our ideas is to use synthetic data.
Generating synthetic data is cheap, there is no risk, but it is necessary to
work with a lot of assumptions which can be limiting.

\subsection{Historical Data}

Typical data about users' performance contains a list of solved tasks and
binary information whether a user's solution is correct ($1$) or incorrect
($0$). A model predicting a user's performance returns values from the interval
$[0, 1]$. Based on this we can fit a new model on a subset of data and test its
predictions comparing them to the rest of data. With respect to accuracy there
is a set of more or less appropriate metrics depending on the fact whether an
absolute or relative value of a prediction is important. This is more deeply
described in~\cite{pelanek2014brief}. From a practical point of view
accuracy is not the only important aspect of the predictive
model~\cite{huang2015framework}. Another important aspect is that a model can
give us deeper insight into a domain. Regarding this it is useful that the
model holds some of the key assumptions, e.g. that a user's knowledge increases with
each exercise or that while fitting its parameters converge to similar values
regardless division of the data.

A similar area to adaptive systems for practice is the are of recommender
systems, e.g. for books or movies. These systems also work with predictive
models to serve appropriate content to their users. There are
studies~\cite{cremonesi2010performance} how accuracy of a model relates to
behavior of a recommender system as a whole. These studies rely only on
historical data. It would be nice to have the same studies in the area of
educational systems. Something similar is presented
in~\cite{yudelson2015small} where the authors quantify saved users' time to get
mastery in case a better model is used. However, it is questionable how valuable
these observations are. In an extreme case, a model predicting $100\%$
performance would be the best from this point of view, but it is definitely not
helpful.

\subsection{New Data}

A classical approach to examining the impact of a system on a user's
behavior is to follow the \emph{pre-test} $\rightarrow$ \emph{intervention}
$\rightarrow$ \emph{post-test} experimental design~\cite{dimitrov2003pretest}.
Usually researchers have full control over participants, often in a
laboratory, but also in an online environment where the participants are
motivated, e.g. using money~\cite{maass2015how}, to finish the whole
experiment. In test phases they are assessed with respect to a measured
variable and in the intervention phase they use the system for a specified
amount of time. Although this approach is very helpful and brings a lot of
interesting observations, it does not scale.

In an online environment we need to periodically deploy new features and
test them only on a subset of users, before we publish them
completely~\footnote{This process is also known as \emph{canary deployment}.} .
Doing this kind of online A/B testing opens new possibilities to
us~\cite{stamper2012rise}. We can collect a large volume of data and make a
cycle of hypothesis testing faster. Unfortunately users in an online environment
enter and quit a system any time, so we can hardly adopt a method of
pre/post-testing. For this reason many studies are focused only on measuring
time a user spends in a system or number of her
interactions~\cite{papousek2015impact,monterrat2015player}
rather than improvement in her performance.

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=.7\textwidth]{figure/interaction_loop}
	\end{center}
	\caption{A schema illustrates an interaction loop between a student model and
		question construction~\cite{niznan2015exploring}.}
	\label{figure:interaction_loop}
\end{figure}

On the other side authors in~\cite{lomas2013optimizing} analyze both the time
and the performance via fitting learning curves on collected data. It is, however,
not clear whether the data are not influenced by collection. For instance, our
system for practicing geography aims at a predefined success
rate~\cite{papousek2014adaptive}, so we can not simply use the collected data
to measure users' performance. Although the interaction loop shown in
Figure~\ref{figure:interaction_loop} is present in many systems, it is usually
ignored.

Another interesting issue is how exactly we should perform online
experiments to maximize the amount of retrieved information and minimize
experimental time~\cite{liu2014towards}. Here lies a great potential in techniques
like multi-armed bandits~\cite{liu2014trading} which can be used to
automatically optimize values of practice parameters over populations of users.

\subsection{Synthetic Data}

Using simulated learners we easily generate synthetic data. The assumptions for
a simulation are usually derived from real traffic. We know the ground truth, how
difficult items are, when a learner mastered a knowledge component and so on.
This allows us to investigate issues which could not be otherwise investigated, like
detection of mastery~\cite{fancsali2013optimal}, learning
curves~\cite{fancsali2013simulated} or the interaction between a model
predicting a user's performance and a system as a
whole~\cite{niznan2015exploring}. In~\cite{niznan2015exploring} we assume that
the optimal practice is given by a set of items practiced using a model with an
access to the ground truth and we compare items practiced using other models to
this set. Authors in~\cite{lopes2015multi} also use simulated learners before
the experiments with real people and state the practice should be personalized
which leads to varied practice sequences. The more diversity is in data, the better
system is.

Experiments with synthetic data are limited by assumptions we have for the
simulated learners. On the other hand, the fewer assumptions we want to have,
the simpler experiments can be. For instance, in our
study~\cite{niznan2015exploring} we did not want to assume anything about
learning, so our simulated practice does not contain repeated interactions with
the same item.

\chapter{Aims of the Thesis}
\label{chapter:aims_of_the_thesis}

\section{Objectives}

The main aim of the thesis is to make learning of facts more
efficient. We plan to design strategies of practicing using multiple-choice
questions in an online environment. We will focus on proper sequencing of
questions and adjusting their difficulty to a learner's needs, both leading to
better learning efficiency. Although the strategies will be applied and
evaluated mainly within an application for practicing geography, the results
should be easily applicable to other similar domains like the learning of
vocabulary.

The particular goals are as follows:

\vspace{-.3cm}
\paragraph*{Model:} As we present in Section~\ref{section:models} the crucial
part of computerized adaptive practice is a model describing a learner's
knowledge. We will investigate models predicting a learner's performance during
learning taking into account the spacing effect and forgetting. These factors
are really important in case of factual knowledge. The considered model should
cooperate with the existing model for prior knowledge~\cite{papousek2014adaptive}
and should be applicable not only offline, but also in an online environment. It
will be deployed within a real system for adaptive practice.

\vspace{-.3cm}
\paragraph{Practice Control:} We plan to develop strategies for sequencing and
question construction with focus on appropriate difficulty, the spacing effect
and suitable distractors for multiple-choice questions. We want to introduce a
mechanism of variable difficulty of distractors, e.g. in the beginning of the
practice the distractors will be easy, later they will be more difficult. The
strategies will highly rely on the predictive model, but we will also build on
existing research using in-lab experiments.

\vspace{-.3cm}
\paragraph{Evaluation:} In Section~\ref{section:evaluation} we address an issue
of evaluation in case of intelligent tutoring systems. For this reason a big
part of the thesis will be dedicated to the evaluation methodology:
\begin{enumerate}
	\item We will propose a methodology to evaluate the impact of adaptive
		practice on a user's learning in an online environment. We want to cover
		both learning efficiency and a learner's willingness to use the tutoring
		system.  We will apply the designed methodology to evaluate a real system
		for adaptive practice.
	\item Using synthetic data we will investigate the interaction loop
		between the student's model and the algorithm for question construction
		more deeply. We will focus mainly on a role of the mechanism of difficulty
		adjustment based on a learner's history.
\end{enumerate}

\section{Expected Outputs}
\begin{enumerate}
	\item The text of the thesis presenting both theoretical and experimental
		results.
	\item A publicly available system for computerized adaptive practice
		implementing developed algorithms for practice control and student
		modeling.
	\item Reviewed publications on relevant international conferences and in
		journals.
		\begin{itemize}
			\item I am currently working on a journal publication
				\textbf{Learner Modeling and Adaptive Practice of Facts}. In this paper I
				am extending an already published analysis~\cite{papousek2015impact}
				examining the impact of adaptive practice on a user's behavior. I am
				focusing mainly on the impact of target difficulty. The paper will be
				published in the journal \emph{User Modeling and User-Adapted Interaction}.
			\item The journal paper \textbf{Adaptive Geography Practice Data Set} is
				already in review process of the \emph{Journal of Learning Analytics}.
				We publish the data set collected by a system providing
				the practice of geography running on \url{www.slepemapy.cz}.
				The paper describes the data set.
			\item In the near future I plan to write publications on the impact of computerized
				adaptive practice on learning compared to its impact on willingness of
				users to stay in the tutoring system and user-reported perception. I
				also plan to publish description of issues related to data collection
				influencing data analysis.
		\end{itemize}
\end{enumerate}



\section{Proposed Plan of Work}

\begin{tabularx}{\textwidth}{rX}
	\rowcolor{white}
	\textbf{Autumn 2015} &
		\vspace{-0.75cm}
		\begin{enumerate}
			\item Design and implementation of methodology for evaluation of the impact
				of adaptive practice on a user's learning.
			\item Evaluation of already existing algorithms for practice control using the
				developed methodology.
			\item Deployment of a new version of the system providing the practice of
				geography that will be able to adopt a new student model.
		\end{enumerate}\\
	\rowcolor{white}
	\textbf{Spring 2016} &
		\vspace{-0.75cm}
		\begin{enumerate}
			\item Design and implementation of a new student model of learning of
				facts.
			\item Development of strategies for practice control cooperating with the
				proposed student model.
		\end{enumerate}\\
	\rowcolor{white}
	\textbf{Autumn 2016} &
		\vspace{-0.75cm}
		\begin{enumerate}
			\item Evaluation of the proposed strategies.
			\item Experiments with synthetic data.
		\end{enumerate}\\
	\rowcolor{white}
	\textbf{Spring 2017} &
		\vspace{-0.75cm}
		\begin{enumerate}
			\item Finishing and submitting the thesis.
		\end{enumerate}
\end{tabularx}

\chapter{Achieved Results}
\label{chapter:achieved_results}

\section{System for Adaptive Practice of Geography}

We have implemented a system providing adaptive practice of geographical
facts. It is available at~\url{www.slepemapy.cz}~\cite{papousek2014adaptive}. This system
estimates users' knowledge and based on the estimation it asks questions of
suitable difficulty. These questions are open or multiple-choice with from 2 to
6 options. They are of 2 different directions ("Where is Germany?" or "What is
the name of the highlighted country?"), see
figure~\ref{figure:example_question}. The questions are then answered using the
"outline map". After a sequence of 10 answers the system shows a user feedback
on her success. Users can also access a visualization of their knowledge using
an open learner model.

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{figure/slepemapy_spain_highlighted}
		\caption{An example of a question asked by \url{www.slepemapy.cz}.}
		\label{figure:example_question}
	\end{center}
\end{figure}

The design of our system is decomposed into 3 steps and each step is handled
independently. More detailed description is available
in~\cite{papousek2014adaptive, papousek2015impact}.

\begin{enumerate}
	\item \emph{Estimation of prior knowledge}. The system tries to estimate the
		probability a user $u$ knows an item $i$ before the first question
		about this item is asked. The estimate is based on previous answers of the
		user $u$ related to other items and on answers of other users about the
		item $i$.
	\item \emph{Estimation of current knowledge}. In this case the system
		estimates the probability a user $u$ knows an item $i$ based on the
		estimation of prior knowledge and a sequence of previous answers of the
		user $u$ about the item $i$.
	\item \emph{Question construction}. Based on the estimation of a user's
		knowledge and other additional information the system constructs a suitable
		question for the user.
\end{enumerate}

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{figure/response_time}
		\caption{Response time and probability that the (next) answer is correct~\cite{papousek2015analysis}.}
		\label{figure:response_time}
	\end{center}
\end{figure}

The system is available for free without any need of registration. However, we
offer a possibility of signing up to help our system with tracking a user's
history. However, we do not collect any information about the identity of users
(e.g. sex or age). So far we collected more than \numprint{11000000} answers
from more than \numprint{100000} (mostly Czech) users. Monthly we collect $\pm$
\numprint{1000000} answers from \numprint{10000} users. The traffic is lower at
weekends and during holidays, which indicates the system is used at schools.
This hypothesis is also supported by the traffic analysis during one
day~\cite{stanislav2015factual}. There are peaks in the traffic corresponding to
lessons at schools in the Czech Republic.

The collected data set serves as an interesting input for further research
within the Adaptive Learning Group\footnote{\url{www.fi.muni.cz/adaptivelearning}},
e.g.~\cite{pelanek2015modeling} modeling students' memory or
\cite{niznan2015student} modeling prior knowledge.
Figure~\ref{figure:response_time} shows the relation between response time and
correctness of an answer. For instance, it shows that in case of a wrong answer
longer response time leads to a higher probability the next answer will be
correct. On the other side in case of correct answers, it is exactly the
opposite. This observation could be used to improve a model for current
knowledge.

\section{Impact of Adaptivity}

In~\cite{papousek2015impact} we analyze the impact of adaptivity of our system
on a user's behavior. We focus mainly on the time spent in the system expressed
by the number of answers per user. We performed online A/B experiments to examine
the role of the designed algorithm for question construction and some of its
parameters. As we describe in Section~\ref{section:practice_control} for the
question construction we firstly need to select an appropriate item and secondly
we need to choose the number of options and options themselves.

In the first experiment we comparedd our approach to algorithms where at least
one of these two steps is random. We found out that both parts of the algorithm
are important. Using random version of the first or the second part leads to
the similar results as in the case of a completely random algorithm.

Since the selection of an appropriate item for practice is based on target
difficulty, we performed the second experiment to find the optimal value for
this parameter. Unfortunately we were not able to find any significant
difference between various values of target difficulty with respect to the number
of answers per user. This is probably caused by the fact that users can choose
different practice contexts (maps) and for different contexts our system
behaves differently, e.g in case of European countries the system can not
provide sufficiently difficult practice for some users and on the other side
for African countries there is sometimes a problem to pick sufficiently easy
questions. Based on this we do not look on the target difficulty with respect to
the number of answers, but on the real difficulty with respect to user-reported
perception\footnote{We ask users to evaluate the practice after $30$, $70$,
$120$ and $200$ answers. Specifically we ask them to express whether it was "Too
difficult", "Appropriate" or "Too easy".}. Using heuristics based on an IP address
we also detect in-school users and compare them to out-of-school users. For an
analysis we divide users according to their success to buckets and for each
bucket we compute the percentage of "Too difficult", "Appropriate" and "Too
easy" records, see Figure~\ref{figure:feedback_by_success}.

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{figure/feedback_by_success_overview}
		\caption{Explicit feedback given by students divided according to their
			previous real success rate~\cite{papousek2015impact}.}
		\label{figure:feedback_by_success}
	\end{center}
\end{figure}

The target difficulty is not constant in our system, we adjust it based on a
user's history. For successful users we make the practice more difficult, for
less successful ones the practice will be easier. This adjustment would make the
choice of the target difficulty less important, so we were interested whether
it has a positive impact on users. The last experiment shows that the group
having the adjustment enabled answers more questions than the group having it
disabled.

\section{Interaction Loop}

Since we adaptively collect data, we analyze it and then we try to improve
the system using acquired insights, we have to take into account the
interaction shown on Figure~\ref{figure:interaction_loop}.
In~\cite{niznan2015exploring} we investigate this interaction loop and the role of
small differences in predictive accuracy using synthetic data. We generate data
using the ground truth model simulating usage of a simplified question
construction algorithm. There are 200 items and 5000 students available in the
system and each student practices 50 items. Each item is practiced by the
student at most once.

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{figure/noise_vs_intersection_number_of_answers}
		\caption{Size of the intersection with the optimal practiced set of items and RMSE
			depending on Gaussian noise in the optimal model (left side). Distribution of answers over
			the items based on the given model (right side)~\cite{niznan2015exploring}.}
		\label{figure:feedback_by_success}
	\end{center}
\end{figure}

Using the ground truth model we declare the practiced set
optimal and then we use different models and see how new practiced sets
differ from the optimal one. In one experiment we gradually add more and more
noise to the ground truth model and look at the practiced set of items. We
found out that a relatively small noise leading to a small \emph{root mean
square error} (RMSE) has a big impact on the practice, see left side of
Figure~\ref{figure:feedback_by_success}. In other experiment we look at the
distribution of collected data across the items. Using the ground truth model
we collect more uniform data than when using other models (except one
corresponding to the completely random uniform distribution), see right side of
Figure~\ref{figure:feedback_by_success}. This shows a risk we face when our
system uses a bad model. We did even more analysis related to the interaction
loop, for more details see~\cite{niznan2015exploring}.

\chapter{Author's Publications}

\begin{enumerate}
	\item \bibentry{papousek2015impact}

		\textit{I performed online experiments examining the algorithm for practice
			control with respect to a user's motivation and then analyzed the collected
			data.}
	\item \bibentry{niznan2015exploring}

		\textit{I did an analysis of feedback loop between a model describing
			a user's knowledge and an algorithm for practice control collecting the
			data. I also examined the impact of the model and its precision on data
			collection.}
	\item \bibentry{papousek2015analysis}

		\textit{I analyzed the relation of response time and correctness of answers.}

	\item \bibentry{papousek2014adaptive}

		\textit{I implemented the predictive model and the algorithm for practice
			control within an application providing the practice of geography. I designed
			the mechanism of difficulty adjustment and selection of distractors in case of
			multiple-choice questions.}
\end{enumerate}

\bibliographystyle{plain}
\bibliography{proposal}

\appendix
\chapter{Enclosed Publications}
\section{Impact of Adaptive Educational System Behaviour on Student Motivation}
\includepdf[pages=-]{paper/papousek2015impact.pdf}
\section{Exploring the Role of Small Differences in Predictive Accuracy using  Simulated Data}
\includepdf[pages=-]{paper/niznan2015exploring.pdf}
\section{An Analysis of Response Times in Adaptive Practice of Geography Facts}
\includepdf[pages=-]{paper/papousek2015analysis.pdf}
\section{Adaptive Practice of Facts in Domains with Varied Prior Knowledge}
\includepdf[pages=-]{paper/papousek2014adaptive.pdf}

\end{document}
